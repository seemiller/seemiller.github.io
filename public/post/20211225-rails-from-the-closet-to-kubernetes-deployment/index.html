<!DOCTYPE html>
<html lang="en-us">
    <head>
		
		
		<meta charset="UTF-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0">

		<title>Rails - From the Closet To Kubernetes - Deployment &middot; Tales from the Command Line</title>

		
		<link rel="stylesheet" href="/css/style.css">
		<link rel="stylesheet" href="/css/fonts.css">
		
		<link rel="icon" href="favicon.ico" />
		<link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png">
		<link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png">
		<link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">

		
		<link href="" rel="alternate" type="application/rss+xml" title="Tales from the Command Line" />
	</head>

    <body>
        		<nav class="nav">
			<div class="nav-container">
				<a href="/">
					
						<h2 class="nav-title">Tales from the Command Line</h2>
					
				</a>
				<ul>
    
    
</ul>
			</div>
		</nav>

        

<main>
	<div class="post">
		<div class="post-info">
    <span>Written by</span>
        
        <br>
        <span>on&nbsp;</span><time datetime="2021-12-25 15:43:53 -0700 MST">December 25, 2021</time>
</div>

		<h1 class="post-title">Rails - From the Closet To Kubernetes - Deployment</h1>
<div class="post-line"></div>

		

		<h1 id="rails---from-the-closet-to-kubernetes---deployment">Rails - From the Closet To Kubernetes - Deployment</h1>
<p>From mid-2007 until early 2020, I helped to develop and maintain a Ruby on Rails application, Pivotal Tracker. I got to see almost the entire lifecycle of this application. When I joined the Tracker team at Pivotal Labs in mid 2007, the app already had its core functionality, but it needed its edges rounded out. For our use as an internal project management application, those rough edges were ok, but we worked to round them out and make it a full-fledged product.</p>
<p>Pivotal Tracker was wildly popular within the company, and our clients loved using it too. Almost too much. A common question when a client engagement neared its end was &ldquo;Can we continue to use Tracker?&rdquo;. Or when they told their friends about it and then the friends called up asking if they could use it. That was a difficult question to answer, as the answer was always no. Tracker was part of our secret sauce and was for internal use only or while there was an active engagement with a client. We also lacked a number of account management features, settings and permissions. Tracker performed its core project management mission admirably, but yeah, rough edges prevented us from allowing outside or public use.</p>
<p>So we set out to smooth those rough edges. Plans were made to add those missing account management features so that we could safely allow outside use without fear of someone accessing a client project. We also added a subscription service so that we could charge users for use of the application. Companies have to keep the lights on somehow right?</p>
<h2 id="in-the-closet">In the Closet</h2>
<p>The entire Pivotal Tracker application was running on a single server. In the closet. And a noisy server as we came to find out, but that&rsquo;s the subject for another story. That single server hosted the Rails application, Apache and the MySQL database. Background jobs, delayed jobs, and maintenance scripts also had to run there as well.</p>
<p>Running an application on a single server is easy. There&rsquo;s 1 server, 1 process, 1 database, 1 DNS record and route. Everything is simple. That is until the performance starts to degrade, or the server goes down. Adding another server complicates things. Suddenly you&rsquo;ll need more infrastructure and process to run the application - load balancers, network routers and switches. The database should have its own server. And yes, backups should be stored on another server or the company NAS. All this means more complexity and expense and people to keep it all running.</p>
<p>Building an application for internal use is easy. Launching it to the public is hard. Opening up Tracker to the public as a subscription service brought a lot of baggage. If we&rsquo;re taking people&rsquo;s money, there is now an expectation that we will actually deliver the service they&rsquo;re paying for. I think reality started to set in.</p>
<p>The idea to create a subscription service was scraped. Instead, the app would be opened to the public for free. This allowed us to sleep easy at night. And since no one was paying for the service, we technically didn&rsquo;t have to provide any sort of uptime expectations. I&rsquo;ll admit that it was a bit disappointing to not flip the switch on the subscription service, but in hindsight, it was genius. With the application now free, the public started to discover it by word of mouth, and it helped the company further establish itself and Pivotal Tracker&rsquo;s popularity.</p>
<p>Pivotal Tracker continued on for another 2 years on that single server. During this time I left the company, but I got pulled back in early 2010. Tracker continued to grow in popularity, and it was time to revisit that subscription service. Everything was still running on that one box, and that was a problem. We needed a better hosting solution. At this time, EngineYard was focusing on Ruby on Rails deployments, and a lot of our clients started to host with them. So, it seemed a natural fit.</p>
<h2 id="out-of-the-closet">Out of the Closet</h2>
<p>Migrating to EngineYard was pretty straight forward, except for an issue using a CDN. Just update the Capistrano deployment configuration and we&rsquo;re deploying to EngineYard. Migrating the database was a snap. Even after 5 years, the size of the database was small enough that we were able to perform a dump and load within a few hours of downtime. Wow! Downtime! When did you last take your application <strong>all the way down</strong> for maintenance?</p>
<p>EngineYard seemed promising at first, but we never really settled in. We were constantly getting plagued by extremely long response times and seemingly random service outages.</p>
<p>So the long response times was a problem on both us and the new deployment at EngineYard. When our application loaded its project page, it queried the database for all stories, comments, commands and user memberships for the project. This operation is pretty expensive and we were constantly poking and tweaking at it to improve performance. Our long term solution for that problem was memcached, but that&rsquo;s another story. So we already knew about the performance issues with the project load, but why was it such a problem at EngineYard? Turns out our database was running on a shared database server that itself was a virtual machine. Part of me died that day. There&rsquo;s no way we would survive with a shared database.</p>
<p>There was still the issue of the seemingly random outages. Two to 4 times a week, for a minute or so, our application would just stop - wouldn&rsquo;t handle requests; open terminals to the virtual machines would just hang. Then everything would just start working again. This went on for a few weeks and was becoming quite a problem. We inquired with some client projects that were deploying to EngineYard so see if they were experiencing similar issues. No one was. Our Product Manager fortunately started to notice a pattern. See, he was also managing an engagement for an up and coming coupon company called Groupon. At the time, Groupon was also deploying to EngineYard. He noticed that every time Groupon did a deployment, our application would get hit with an outage. Do a little digging, and we find out that Groupon&rsquo;s footprint is considerable larger than ours, and our virtual machines are sharing the same bare metal and network gear as Groupon. Once again, virtual machines running on shared servers bites us.</p>
<h2 id="hybrid-cloud">Hybrid Cloud</h2>
<p>These experiences left a sour taste for infrastructure where our virtual machines co-mingled with other &ldquo;noisy neighbors&rdquo;. Unfortunately, this meant we started the search for a new hosting provider again. It wasn&rsquo;t long before we found a shop out of Seattle, Washington, called BlueBox. I don&rsquo;t recall what specifically drove us to chose them, but they had a hosting model to our liking. We could create an environment that was a hybrid between virtual and bare-metal servers. Application and utility servers were all virtual. We could easily spin up others for memcached, delayed jobs, and easily create demo and staging environments. The bare metal servers hosting all of those virtual machines were ours - no more noisy neighbors. Much to my delight, the database was also back on bare-metal.</p>
<p>BlueBox was a fantastic place to call home. The servers were fast and reliable. Their support was top-notch too. They had a small staff, but frequently helped us out with some code or database optimizations when we got stuck. We basically settled in for 4 or 5 years. This comfort did have a bit of a downside - we missed out on the beginnings of the Cloud era, and all the innovations that came with it.</p>
<p>There were a few factors that contributed to our eventual move to Amazon Web Services. In 2013 Pivotal Labs was acquired by EMC. My TL;DR of the acquisition was this: A client, Greenplum, which was owned by EMC, had such a favorable experience with us and was so enamored with our process and culture, convinced EMC to buy us out. The real motivator behind this was that EMC had a struggling engineering project that needed help. That was CloudFoundry. Pivotal Labs took over development of CloudFoundry and made it what it is today. Other companies contributed heavily to CloudFoundry as well, such as IBM. In 2015, IBM bought BlueBox, our much beloved hosting provider. We also started having some issues with our database server, and BlueBox was hesitant to provision a new one. After months of questioning, it came out that BlueBox was being directed to shut down its traditional hosting services (that we were still using) and migrate all customers to IBM&rsquo;s flavor of CloudFoundry. This was certainly a problem. Pivotal Labs' flagship application running on a competitor&rsquo;s version of CloudFoundry? I think not. This spurred a migration effort, Project ExBox, to get out of IBM BlueBox and on to a Pivotal CloudFoundry instance running on AWS.</p>
<h2 id="aws">AWS</h2>
<p>The migration to AWS was arduous. We advertised 5 months, but in reality I think it was 9+. There were so many places in the code that needed tweaking to run on a platform like CloudFoundry. This meant massive amounts of <code>if... else...</code> statements littering the code. We had to overhaul our continuous integration setup. Institute pipelines for testing, deploying, creating containers, running migrations, backups. Crash course in containerization as everything needed to run in a container. BOSH became our new worst nightmare. We had to migrate our (now multi-100GB) database to RDS. New DNS and TLS certificates. Load and performance testing. It was either a DevOps Engineer&rsquo;s worst nightmare or dream job. It took our team months to make all the changes and verify our migration plan. Then one donut fueled morning in October 2016, we took Tracker down for maintenance and made the move.</p>
<p>From the moment that we moved to AWS, there was pressure to move off it. Turns out running a CloudFoundry instance on AWS was not cheap, something like $75-100K a month. That was a significant bump in our hosting costs. Unfortunately, it was the easiest place to run CloudFoundry. AWS seemed to be the happy path for CloudFoundry development, make it work there first. This expense had us playing games like using spot instances and shutting down our CI pipelines for the night and weekends. Personally, this was a good time as I was learning about AWS and running applications in the Cloud. So this was now more of a dream job instead of a nightmare.</p>
<h2 id="gcp">GCP</h2>
<p>About this time, Pivotal started to partner with Google to make CloudFoundry compatible with Google Cloud Platform. This partnership hatched the plan to accelerate a move off of AWS. THe idea was that Pivotal Tracker could dog food CloudFoundry on GCP. And our new Google partnership came with some partner cost savings. So with just a few months since our move to AWS, we started another migration project.</p>
<p>The migration to GCP was considerably easier than the move to AWS. Since Tracker was now running on CloudFoundry, in theory, we were insulated from the underlying cloud platform and hardware. As long as CloudFoundry had the drivers and providers, Tracker should work just fine. For the most part, in theory translated into in real life. We only needed 1-2 months of engineering time to made changes specific to GCP and validate that Tracker would run. Toss in another month or 2 for load and performance testing and data migration. By the end of July 2017, Tracker was running on GCP.</p>
<p>We settled in with Google Cloud Platform quite well. Costs were under control. Servers, virtual machines and databases all provided increased performance. But the network! Google&rsquo;s worldwide fibre network was amazing! Latency, response times and basically anything network related saw significant increases in performance. The GCP move also came with the added partnership of our CloudOps team in Dublin, Ireland. CloudOps EU had agreed to take ownership of running the CloudFoundry foundation, allowing us to get back to focusing on just Tracker. Managing a CloudFoundry installation is a lot of work!. This was a real win, but not just for the Tracker Team. CloudOps was able to provide Pivotal with a live, production testbed for new releases and processes for managing a CloudFoundry installation. This arrangement provided an enormous amount of benefit to Pivotal Tracker, CloudFoundry, and all of our clients who benefited from the innovations that the CloudOps made while maintaining the foundation.</p>
<p>However, that arrangement also spelled the end of Pivotal Tracker running on CloudFoundry. This is also the final step in our journey to Kubernetes. In the intervening years, EMC was acquired by Dell, and then Pivotal was IPO&rsquo;d back out on its own. However, we were still majority owned by Dell. I&rsquo;m certainly not going to claim that I understand how corporations work when it comes to earnings, debt and taxes, but a decision was made to have VMware, also majority owned by Dell, acquire Pivotal. This had some bad news for us.</p>
<h2 id="kubernetes">Kubernetes</h2>
<p>One of the outcomes of the VMware acquisition was the closure of the Dublin, Ireland office. This is where the CloudOps team was based. No office meant no CloudOps team. No CloudOps team meant a big question as to who would be managing our CloudFoundry installation. The situation degraded even quicker than we expected. Most of the CloudOps team was focused on figuring out their future, with or without VMware, so they we understandably distracted. And remember I mentioned that we were dog-fooding new releases of software for CloudFoundry? Well, a bug was introduced into a piece of networking software that messed with DNS resolution. The end result of this to us was that we could no longer deploy new releases. Some valiant attempts to rectify the situation were made by the remaining CloudOps team members but to no avail. The picture was clear to us though. The Tracker Team simply did not have the expertise to manage that CloudFoundry foundation and we needed to move, again.</p>
<p>At this point, in early 2020, our path was pretty clear. Kubernetes was eating CloudFoundry&rsquo;s lunch on a daily basis. All the momentum was pointing us to make the move to Kubernetes. I joked that I would only be a part of the migration if we moved to Azure, so that I could get the Trifecta of the big 3 cloud providers. Having everything already running on GCP was part of what made the move to Google Kubernetes Engine so easy - no database to migrate - no major DNS or networking changes - app already coded to run in the Cloud. The majority of the initial work was to change the pipelines to deploy to Kubernetes instead of CloudFoundry, and that work was pretty quick, maybe a couple weeks? I seem to recall going from zero Kubernetes to production Kubernetes deployments in about 6 weeks. The move to Kubernetes was my final work with Pivotal Tracker. From a server in the closet to Kubernetes on GCP.</p>
<p>I was really amazed at just how easy it was to use Kubernetes. And the community around Kubernetes astounded me as well. All of these services and software community built. That&rsquo;s what eventually led me to help open sourcing VMware&rsquo;s flavor of Kubernetes. To be a part of that community and to give back.</p>
<h2 id="deploying-a-rails-app">Deploying a Rails App</h2>
<p>So if I were to start this story all over again now, I would most definitely start it with Kubernetes. Not sure if I would stick with Rails, but at this point, it&rsquo;s what I know. So I&rsquo;d like to show deploying a Ruby on Rails application to Kubernetes.</p>
<p>So let&rsquo;s dive in and see what we need to deploy a Ruby on Rails application on Kubernetes.</p>
<ul>
<li>Rails app</li>
<li>Container</li>
<li>Kubernetes cluster</li>
<li>Database Deployment</li>
<li>Application Deployment</li>
</ul>
<p>In developing this guide, I used the following hardware, software, and services.</p>
<ul>
<li>Apple Macbook Pro</li>
<li>Amazon Web Services</li>
<li>ttl.sh</li>
<li>MySQL 8.0.27</li>
<li>Rails 6.1.4.1</li>
<li>Ruby 3.0.2</li>
<li>VMware Tanzu Community Edition</li>
</ul>
<h3 id="rails-application">Rails Application</h3>
<p>To start, we need a Rails application. We can either create one from scratch, or use an existing application. To keep things accessible and simple, we&rsquo;ll just use the Blog application built in the <a href="https://guides.rubyonrails.org/v6.0/getting_started.html">Ruby on Rails - Getting Started</a> guide. I&rsquo;ve already followed the guide and committed it to a GitHub <a href="https://github.com/seemiller/rails-blog">repository</a>. So you can bring your own app, or just clone this one. I did deviate from the guide by using a MySQL database instead of SQLite. Having a separate database makes for a more thorough demonstration.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">git clone git@github.com:seemiller/rails-blog.git
</code></pre></div><p>Or if you&rsquo;re creating a new application from scratch, here&rsquo;s the command I used to create the basic application. You&rsquo;ll be on your own to create a scaffold or other components.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">rails new rails-blog --minimal --database mysql --webpack<span style="color:#f92672">=</span>react
</code></pre></div><h3 id="container">Container</h3>
<p>Kubernetes is really nothing more than an extensible container orchestration platform. So we need to put our application into a container. We can do this with a Dockerfile. Change into the rails-blog directory and lets take a look at the Dockerfile.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">cd rails-blog

cat Dockerfile
</code></pre></div><p>The Dockerfile should look like this.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-dockerfile" data-lang="dockerfile"><span style="color:#66d9ef">FROM</span><span style="color:#e6db74"> ruby:3.0.2</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> curl https://deb.nodesource.com/setup_12.x | bash<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> curl https://dl.yarnpkg.com/debian/pubkey.gpg | apt-key add -<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> echo <span style="color:#e6db74">&#34;deb https://dl.yarnpkg.com/debian/ stable main&#34;</span> | tee /etc/apt/sources.list.d/yarn.list<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> apt-get update <span style="color:#f92672">&amp;&amp;</span> apt-get install -y build-essential <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>                                         nodejs <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>                                         yarn <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>                                         vim <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>                                         --no-install-recommends <span style="color:#f92672">&amp;&amp;</span> <span style="color:#ae81ff">\
</span><span style="color:#ae81ff"></span>    rm -rf /var/lib/apt/lists/*<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">ENV</span> RAILS_ENV production<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">ENV</span> RAILS_LOG_TO_STDOUT true<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> mkdir /app<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">WORKDIR</span><span style="color:#e6db74"> /app</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> Gemfile ./<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> gem install bundler<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> bundle install<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">COPY</span> . .<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">RUN</span> rake assets:precompile<span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">EXPOSE</span><span style="color:#e6db74"> 3000</span><span style="color:#960050;background-color:#1e0010">
</span><span style="color:#960050;background-color:#1e0010"></span><span style="color:#66d9ef">CMD</span> [<span style="color:#e6db74">&#34;rails&#34;</span>, <span style="color:#e6db74">&#34;server&#34;</span>, <span style="color:#e6db74">&#34;-b&#34;</span>, <span style="color:#e6db74">&#34;0.0.0.0&#34;</span>]<span style="color:#960050;background-color:#1e0010">
</span></code></pre></div><p>This is a pretty straight-forward Dockerfile. We start with the Ruby 3.0.2 base image and add in the needed things like node, yarn, and build tools. Some environment variables are set as well to indicate that this is our &ldquo;production&rdquo; environment and where to log Rails' output to. It is important to have Rails log to STDOUT as this is where Kubernetes expects all to output to go. Kubernetes can then pipe all this output into log monitoring services such as fluentd. Next we copy our application source code and run bundle to get our gems. In a full blown production pipeline this is a good place to &ldquo;pre-bake&rdquo; an image to speed things up. Assets are compiled and we expose port 3000 and give the command to run the server.</p>
<p>Build the image and push it up.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">docker build --tag ttl.sh/seemiller/rails-blog:1d .

docker push ttl.sh/seemiller/rails-blog:1d
</code></pre></div><h3 id="kubernetes-cluster">Kubernetes Cluster</h3>
<p>For my Kubernetes cluster, I&rsquo;m going to use Tanzu Community Edition, from VMware. Guess I&rsquo;m a bit biased as to the choice of this distribution, so I&rsquo;ll admit that I have made some contributions to this distro.</p>
<p>This post isn&rsquo;t about deploying Kubernetes. So to keep things on track, I&rsquo;ll refer you to the <a href="https://tanzucommunityedition.io/docs/latest/getting-started/">Getting Started</a> documentation for deploying Tanzu Community Edition. I used a managed cluster on Amazon Web Services. You are of course free to use any distribution that you prefer or have easy, and possibly free, access to.</p>
<p>Once a cluster is up and running, create a namespace to contain the blog application. To help keep track of things, assign a label to the namespace as well.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create namespace blog
kubectl label namespace blog app<span style="color:#f92672">=</span>blog
</code></pre></div><p>An equivalent manifest file is located in the <code>kubernetes</code> directory that could be applied instead.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/namespace.yaml
</code></pre></div><p>Learn more about <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">namespaces</a> and <a href="https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/">labels</a> in the official Kubernetes documentation.</p>
<h3 id="database">Database</h3>
<p>If you have any experience at all with Rails, you know that you can&rsquo;t do anything without a database. Ok, you can serve static files, but there are better ways to do that than by running a Rails server. Personally, I&rsquo;m not a huge fan of running a database on any type of virtual or containerized platform. In my opinion, a database should be installed on a big honkin' bare metal server with lots of CPU, lots of RAM and lots of disk. And if you can afford it, there&rsquo;s an identical machine setting next to it in the rack. Except this other server is on a different electrical circuit and network stack. If you can&rsquo;t have bare metal, opt for a service like AWS RDS or GCP CloudSQL. The managed database services will work pretty well for most use cases, and they come with bells and whistles like snapshots, backups, redundancies in different regions and zones. Pivotal Tracker started with MySQL running alongside the Rails application in the closet. At BlueBox we had <a href="https://www.percona.com/software/mysql-database/percona-server">Percona</a> running on bare-metal, and it was awesome. AWS RDS and GCP CloudSQL rounded out our databases in the Cloud.</p>
<p>However, for this exercise, we&rsquo;ll deploy plain old MySQL to our cluster. Why MySQL and not Postgres or some other database? To be honest, it&rsquo;s what I&rsquo;ve always used. Pivotal Tracker used it for years, and I used it before joining Pivotal Labs. It&rsquo;s what I know and am comfortable with. It might not be web scale, but it gets the job done. So that&rsquo;s what I&rsquo;m going to deploy. It also helps that the Kubernetes documentation has a nice <a href="https://kubernetes.io/docs/tutorials/stateful-application/mysql-wordpress-persistent-volume/">example</a> already worked up with MySQL, which I&rsquo;ve drawn inspiration from.</p>
<p>In deploying our MySQL database, we need to declare three things to Kubernetes:</p>
<ul>
<li>Service</li>
<li>Persistent Volume/Claim</li>
<li>Deployment</li>
</ul>
<p>Let&rsquo;s start with the service. The service will make the database application available to the other pods in the cluster. The selector <code>app: blog</code> will allow the pods in our future Rails deployment to map to the correct service. By specifying <code>clusterIP: None</code> we are disabling load-balancing and not allocating a cluster IP address. We will have to reference our service by DNS. MySQL&rsquo;s well known port is 3306, so we declare the service should use 3306.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
  <span style="color:#f92672">labels</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">selector</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
  <span style="color:#f92672">clusterIP</span>: <span style="color:#ae81ff">None</span>
  <span style="color:#f92672">ports</span>:
    - <span style="color:#f92672">name</span>: <span style="color:#e6db74">&#34;mysql&#34;</span>
      <span style="color:#f92672">port</span>: <span style="color:#ae81ff">3306</span>
      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">3306</span>
</code></pre></div><p>Let&rsquo;s create the service by applying the manifest.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/mysql-service.yaml
</code></pre></div><p>Learn more about <a href="https://kubernetes.io/docs/concepts/services-networking/service/">services</a> in the official Kubernetes documentation.</p>
<h3 id="persistent-volume-claim">Persistent Volume Claim</h3>
<p>A database needs a disk to write its data to. Otherwise, we might as well use /dev/null, which I hear is fast and web scale. Kubernetes provides disk via Persistent Volume Claims, or pvc&rsquo;s. Since this is just an example application, we don&rsquo;t need much, just a small disk that provides Read/Write access to a single node. We&rsquo;ll allocate the disk space here, and wire it up in the deployment. We will declare a persistant volume, and then a claim to that volume.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolume</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-pv</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">capacity</span>:
    <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1Gi</span>
  <span style="color:#f92672">volumeMode</span>: <span style="color:#ae81ff">Filesystem</span>
  <span style="color:#f92672">accessModes</span>:
    - <span style="color:#ae81ff">ReadWriteOnce</span>
  <span style="color:#f92672">hostPath</span>:
    <span style="color:#f92672">path</span>: <span style="color:#e6db74">&#34;/var/lib/mysql&#34;</span>
  <span style="color:#f92672">claimRef</span>:
    <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-pvc</span>
    <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">PersistentVolumeClaim</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-pvc</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
  <span style="color:#f92672">labels</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">accessModes</span>:
    - <span style="color:#ae81ff">ReadWriteOnce</span>
  <span style="color:#f92672">resources</span>:
    <span style="color:#f92672">requests</span>:
      <span style="color:#f92672">storage</span>: <span style="color:#ae81ff">1Gi</span>
  <span style="color:#f92672">volumeName</span>: <span style="color:#ae81ff">mysql-pv</span>
</code></pre></div><blockquote>
<p>Note that we&rsquo;re using a hostPath in the Persistent Volume. This is really only good for single node clusters. If you really want this disk to work in a more production like environment, you&rsquo;ll want to use a different <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/#types-of-persistent-volumes">type of persistent volume</a> that aligns with your infrastructure.</p>
</blockquote>
<p>Create the persistent volume claim by applying the manifest.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/mysql-storage.yaml
</code></pre></div><p>Learn more about <a href="https://kubernetes.io/docs/concepts/storage/persistent-volumes/">persistent volume/claims</a> in the official Kubernetes documentation.</p>
<h3 id="deployment">Deployment</h3>
<p>The Deployment tells Kubernetes about the containerized application that you want to run. You can specify how many pods to run, environment variables, ports and volume mounts. Deployments can be scaled, rolled out, and rolled back. We&rsquo;ll specify the container image that we want to run, which for us is the MySQL 8.0.27 image.The persistent disk that was created in the previous step will be mapped here. The name of the PVC is used in the volumes specification, and we map it to a mount path that MySQL will use to store our database.</p>
<p>If you notice in the container spec, there is a reference to a secret for the root user password. In conjunction with creating this deployment, we need to create a secret. We&rsquo;ll need a generic secret created from a literal value. That value will get base64 encoded and stored in the Kubernetes etcd process. The deployment will inject this value into the environment of the container that is running the database. There are other ways and means of handling secrets, but that&rsquo;s a topic for another time.</p>
<p>Create the secret.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create secret generic mysql-pass --from-literal<span style="color:#f92672">=</span>password<span style="color:#f92672">=</span>super-secret-password --namespace<span style="color:#f92672">=</span>blog
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get secret/mysql-pass --namespace blog --output yaml
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">data</span>:
  <span style="color:#f92672">password</span>: <span style="color:#ae81ff">c3VwZXItc2VjcmV0LXBhc3N3b3Jk</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-pass</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
</code></pre></div><blockquote>
<p>Notice how the value for the password is base64 encoded.</p>
</blockquote>
<p>With the secret in place, we can create the deployment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/mysql-deployment.yaml
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
  <span style="color:#f92672">labels</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">selector</span>:
    <span style="color:#f92672">matchLabels</span>:
      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
  <span style="color:#f92672">strategy</span>:
    <span style="color:#f92672">type</span>: <span style="color:#ae81ff">Recreate</span>
  <span style="color:#f92672">template</span>:
    <span style="color:#f92672">metadata</span>:
      <span style="color:#f92672">labels</span>:
        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">blog</span>
    <span style="color:#f92672">spec</span>:
      <span style="color:#f92672">containers</span>:
      - <span style="color:#f92672">image</span>: <span style="color:#ae81ff">mysql:8.0.27</span>
        <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql</span>
        <span style="color:#f92672">env</span>:
        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">MYSQL_ROOT_PASSWORD</span>
          <span style="color:#f92672">valueFrom</span>:
            <span style="color:#f92672">secretKeyRef</span>:
              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-pass</span>
              <span style="color:#f92672">key</span>: <span style="color:#ae81ff">password</span>
        <span style="color:#f92672">ports</span>:
        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">3306</span>
          <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql</span>
        <span style="color:#f92672">volumeMounts</span>:
        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-persistent-storage</span>
          <span style="color:#f92672">mountPath</span>: <span style="color:#ae81ff">/var/lib/mysql</span>
      <span style="color:#f92672">volumes</span>:
      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">mysql-persistent-storage</span>
        <span style="color:#f92672">persistentVolumeClaim</span>:
          <span style="color:#f92672">claimName</span>: <span style="color:#ae81ff">mysql-pvc</span>
</code></pre></div><p>Check the status of the deployment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deployments --namespace blog

NAME    READY   UP-TO-DATE   AVAILABLE   AGE
mysql   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           5m
</code></pre></div><p>When ready is <code>1/1</code> and available is <code>1</code>, the application should be up and running. Verify by taking a look at the logs for the MySQL application.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl logs --namespace blog deployment/mysql

2021-10-23 05:01:36+00:00 <span style="color:#f92672">[</span>Note<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Entrypoint<span style="color:#f92672">]</span>: Entrypoint script <span style="color:#66d9ef">for</span> MySQL Server 8.0.27-1debian10 started.
2021-10-23 05:01:36+00:00 <span style="color:#f92672">[</span>Note<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Entrypoint<span style="color:#f92672">]</span>: Switching to dedicated user <span style="color:#e6db74">&#39;mysql&#39;</span>
2021-10-23 05:01:36+00:00 <span style="color:#f92672">[</span>Note<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Entrypoint<span style="color:#f92672">]</span>: Entrypoint script <span style="color:#66d9ef">for</span> MySQL Server 8.0.27-1debian10 started.
2021-10-23 05:01:36+00:00 <span style="color:#f92672">[</span>Note<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Entrypoint<span style="color:#f92672">]</span>: Initializing database files
2021-10-23T05:01:36.702659Z <span style="color:#ae81ff">0</span> <span style="color:#f92672">[</span>System<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>MY-013169<span style="color:#f92672">]</span> <span style="color:#f92672">[</span>Server<span style="color:#f92672">]</span> /usr/sbin/mysqld <span style="color:#f92672">(</span>mysqld 8.0.27<span style="color:#f92672">)</span> initializing of server in progress as process <span style="color:#ae81ff">43</span>
...
</code></pre></div><p>Looks like the database is up and running! We can move on to deploying the Rails application and configuring the database.</p>
<p>Learn more about <a href="https://kubernetes.io/docs/concepts/workloads/controllers/deployment/">deployments</a> and <a href="https://kubernetes.io/docs/concepts/configuration/secret/">secrets</a> in the official Kubernetes documentation.</p>
<h3 id="rails-deployment">Rails Deployment</h3>
<p>We&rsquo;ll follow a similar process for deploying the Rails application as we did the MySQL database. We will need to define a deployment, service and secrets. In addition, an ingress will also need to be declared. The ingress will allow web traffic to be routed from outside the cluster to the Rails application.</p>
<h4 id="service">Service</h4>
<p>Let&rsquo;s start with the service. The Rails application is listening on port 3000 as was defined in the Dockerfile. So we need to map port 80 to port 3000. Once again, we&rsquo;ll specify a clusterIP of none.</p>
<p>You can create the service with the kubectl command, or apply the yaml file directly.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create service clusterip rails --namespace<span style="color:#f92672">=</span>blog --clusterip<span style="color:#f92672">=</span>None --tcp<span style="color:#f92672">=</span>80:3000
</code></pre></div><p>or just apply the existing manifest file.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/rails-service.yaml
</code></pre></div><p>The service manifest will look as follows:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Service</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">labels</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">clusterIP</span>: <span style="color:#ae81ff">None</span>
  <span style="color:#f92672">ports</span>:
    - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">80-3000</span>
      <span style="color:#f92672">port</span>: <span style="color:#ae81ff">80</span>
      <span style="color:#f92672">protocol</span>: <span style="color:#ae81ff">TCP</span>
      <span style="color:#f92672">targetPort</span>: <span style="color:#ae81ff">3000</span>
  <span style="color:#f92672">selector</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">type</span>: <span style="color:#ae81ff">ClusterIP</span>
</code></pre></div><h4 id="secrets">Secrets</h4>
<p>At a minimum, Rails needs a couple of secrets to function, the session key and the database URL.</p>
<p>Create a session key using the rails secret command.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">rails secret | base64

ZDYwOTU0MzJlNDc3NjM5OGI4MDQ2ZTczODE3YmYxMzQ2NzlkNmI0ZDlmYjdkYjc5ODExMjli
MjAxNzc5OGMxNzZhNDA1Yjc4NDllNzUwOTgzMTU2YjM1ODNlZWY2ZDA0YWIyMjY2NjUyYTMw
ZWZlMmU3YjdjZTVlNDkyNDczZjEK
</code></pre></div><p>The database URL of course tells Rails how to find the database. You can specify individual parameters in the Rails database.yaml config file, or use a more succinct approach, the DATABASE_URL. The DATABASE_URL allows you to specify all the connection parameters in one. It has the following format:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mysql2://myuser:mypass@example.com/mydatabase
</code></pre></div><p>To fill out the DATABASE_URL, we&rsquo;ll need the root password that we created for MySQL earlier, and the DNS name for the MySQL service. Kubernetes provides DNS names for services running the cluster. It follows a convention:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">&lt;service-name&gt;.&lt;namespace&gt;.svc.cluster.local
</code></pre></div><p>So in our situation, the DNS name for the MySQL database service is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">mysql.blog.svc.cluster.local
</code></pre></div><p>Using that DNS name, we can build our DATABASE_URL connection string.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">echo <span style="color:#e6db74">&#34;mysql2://root:super-secret-password@mysql.blog.svc.cluster.local/rails_blog_production&#34;</span> | base64
</code></pre></div><p>Learn more about <a href="https://guides.rubyonrails.org/configuring.html#configuring-a-database">database configuration options</a> in the Rails documentation and <a href="https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/">DNS for Services</a> in the Kubernetes documentation.</p>
<p>Armed with our secrets, we can create a secrets manifest file and add them to the cluster.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Secret</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails-secrets</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">type</span>: <span style="color:#ae81ff">Opaque</span>
<span style="color:#f92672">data</span>:
  <span style="color:#f92672">database-url</span>: |<span style="color:#e6db74">
</span><span style="color:#e6db74">    bXlzcWwyOi8vcm9vdDpzdXBlci1zZWNyZXQtcGFzc3dvcmRAbXlzcWwuYmxvZy5zdmMuY2x1
</span><span style="color:#e6db74">    c3Rlci5sb2NhbC9yYWlsc19ibG9nX3Byb2R1Y3Rpb24K</span>    
  <span style="color:#f92672">secret-key-base</span>: |<span style="color:#e6db74">
</span><span style="color:#e6db74">    Y2U5NDE4OWZhZGYwYTRhZTg2ZmZkM2NlMjEyZjJkYzEyMzFkMjI5ZTNjNDcwMjk4OGJmMjRj
</span><span style="color:#e6db74">    MzAyMWNhZWJlNWI4ZTRmNWExZjQxM2JhYWVjMTU0MDRiZDE2MmNkYzZlY2M5NWZjMGQ1Njhi
</span><span style="color:#e6db74">    MGFmZTljMTY1NTY1NGMyNWU4NzUK</span>    
</code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/rails-secret.yaml
</code></pre></div><blockquote>
<p>For a real production application you of course would not want to commit your secret values to your source control. There are better and more secure means to handle secrets that are the subject of another story.</p>
</blockquote>
<h4 id="deployment-1">Deployment</h4>
<p>We&rsquo;re ready for the deployment now, and once again this is very similar to the MySQL deployment we created earlier. Pretty straight-forward deployment, the only things of note are exposing the application on port 3000 and adding references to our secret values.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml">---
<span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">apps/v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Deployment</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">labels</span>:
    <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">replicas</span>: <span style="color:#ae81ff">1</span>
  <span style="color:#f92672">selector</span>:
    <span style="color:#f92672">matchLabels</span>:
      <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">template</span>:
    <span style="color:#f92672">metadata</span>:
      <span style="color:#f92672">labels</span>:
        <span style="color:#f92672">app</span>: <span style="color:#ae81ff">rails</span>
    <span style="color:#f92672">spec</span>:
      <span style="color:#f92672">containers</span>:
      - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails</span>
        <span style="color:#f92672">image</span>: <span style="color:#ae81ff">ttl.sh/seemiller/rails-blog:1d</span>
        <span style="color:#f92672">ports</span>:
        - <span style="color:#f92672">containerPort</span>: <span style="color:#ae81ff">3000</span>
        <span style="color:#f92672">env</span>:
        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">DATABASE_URL</span>
          <span style="color:#f92672">valueFrom</span>:
            <span style="color:#f92672">secretKeyRef</span>:
              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails-secrets</span>
              <span style="color:#f92672">key</span>: <span style="color:#ae81ff">database-url</span>
        - <span style="color:#f92672">name</span>: <span style="color:#ae81ff">SECRET_KEY_BASE</span>
          <span style="color:#f92672">valueFrom</span>:
            <span style="color:#f92672">secretKeyRef</span>:
              <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails-secrets</span>
              <span style="color:#f92672">key</span>: <span style="color:#ae81ff">secret-key-base</span>
</code></pre></div><p>Apply this deployment.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl apply --filename kubernetes/rails-deployment.yaml
</code></pre></div><p>Wait for it to become available.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get deployments --namespace blog

NAME    READY   UP-TO-DATE   AVAILABLE   AGE
mysql   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           3d16h
rails   1/1     <span style="color:#ae81ff">1</span>            <span style="color:#ae81ff">1</span>           3d
</code></pre></div><p>Our Rails application is now deployed to Kubernetes!</p>
<h4 id="database-setup">Database Setup</h4>
<p>As mentioned earlier, you can&rsquo;t do anything with Rails without a database. Unfortunately, I have yet to come across an elegant means of initializing the database. It feels crude, but a simple <code>exec</code> command will get us going. In a fully built out application with a CI/CD pipeline, you could run migrations in a Job as part of the deployment process, but that is overkill for us here at the moment.</p>
<p>Use kubectl to create the database and run the migrations.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl exec deployment/rails -it --namespace blog -- rails db:create db:migrate
</code></pre></div><h4 id="ingress">Ingress</h4>
<p>The final step in making the Blog application available is to create an Ingress. An ingress creates a load balancer or endpoint that external processes can use to make requests of services running inside our cluster. Typically, this is for HTTP requests.</p>
<p>You can create an ingress on the fly using the kubectl command. In this command, we are mapping all requests to this ingress to port 80 of the <code>rails</code> service. If you recall, we created a service for the Rails app that listens on port 80 and targets port 3000 on any object with an <code>app: rails</code> label.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl create ingress rails --namespace blog --rule<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/*=rails:80&#34;</span>
</code></pre></div><p>This creates our ingress object.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-yaml" data-lang="yaml"><span style="color:#f92672">apiVersion</span>: <span style="color:#ae81ff">networking.k8s.io/v1</span>
<span style="color:#f92672">kind</span>: <span style="color:#ae81ff">Ingress</span>
<span style="color:#f92672">metadata</span>:
  <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails</span>
  <span style="color:#f92672">namespace</span>: <span style="color:#ae81ff">blog</span>
<span style="color:#f92672">spec</span>:
  <span style="color:#f92672">rules</span>:
  - <span style="color:#f92672">http</span>:
      <span style="color:#f92672">paths</span>:
      - <span style="color:#f92672">backend</span>:
          <span style="color:#f92672">service</span>:
            <span style="color:#f92672">name</span>: <span style="color:#ae81ff">rails</span>
            <span style="color:#f92672">port</span>:
              <span style="color:#f92672">number</span>: <span style="color:#ae81ff">80</span>
        <span style="color:#f92672">path</span>: <span style="color:#ae81ff">/</span>
        <span style="color:#f92672">pathType</span>: <span style="color:#ae81ff">Prefix</span>
</code></pre></div><p>We can get the ingresses in our namespace to get the external IP address.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">kubectl get ingress --namespace blog

NAME    CLASS    HOSTS   ADDRESS                                                                  PORTS   AGE
rails   &lt;none&gt;   *       a65e9ab6f9ea449149814be66c783071-339151308.us-east-1.elb.amazonaws.com   <span style="color:#ae81ff">80</span>      5m
</code></pre></div><p>Your IP address will vary depending on where your cluster is running. AWS provides a nice, unmemorable address that can easily be mapped to a domain name in their Route53 DNS service. In the spirit of keeping things simple, I&rsquo;m going to save the details of updating DNS and implementing TLS for another story.</p>
<p>With the ingress created, copy/paste the address into your favorite browser and enjoy the sample Rails Blog application.</p>
<p>Learn more about <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/">ingresses</a> in the official Kubernetes documentation.</p>
<h2 id="conclusion">Conclusion</h2>
<p>We&rsquo;ve come a long way from deploying apps on noisy servers running the closet. There&rsquo;s still something to be said for the simplicity of just racking a server, installing an OS, deploying some code, updating DNS and profiting. When you&rsquo;re just starting out, or for a toy/learning application that&rsquo;s a perfectly viable route. But eventually that model doesn&rsquo;t scale - especially if you&rsquo;re trying to grow a business around it. Having a platform like Kubernetes to build your application on makes a world of difference. With many proven patterns, software services, and a thriving user community to call upon for help, you can focus on your application and just know that the deployment is not a concern. As a DevOps/SRE/Full Stack Engineer, Kubernetes would have made my life so much easier on this journey from the closet to the Cloud.</p>


		
	</div>

	<div class="pagination">
		<a href="/post/20211225-rails-from-the-closet-to-kubernetes-scaling/" class="right arrow">&#8594;</a>

		<a href="#" class="top">Top</a>
	</div>
</main>


        		<footer>
			
			<span>
			&copy; <time datetime="2021-12-25 17:02:31.156424 -0700 MST m=&#43;0.063058841">2021</time> . Made with <a href='https://gohugo.io'>Hugo</a> using the <a href='https://github.com/EmielH/tale-hugo/'>Tale</a> theme.
			</span>
		</footer>

    </body>
</html>
